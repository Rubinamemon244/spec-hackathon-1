# Data Model: AI-Robot Brain (NVIDIA Isaac) Educational Module

## Overview
This document defines the key entities, data structures, and relationships for the educational content about NVIDIA Isaac tools. These represent the conceptual models that students will learn and work with.

## Simulation Environment Entities

### Virtual Scene
- **Attributes**:
  - name: string (unique identifier for the scene)
  - description: string (educational purpose of the scene)
  - objects: array of SceneObject (physical entities in the scene)
  - lighting: LightingConfig (lighting properties and effects)
  - physics_properties: PhysicsConfig (gravity, friction, etc.)
  - sensors: array of SensorConfig (sensor configurations in the scene)

### SceneObject
- **Attributes**:
  - id: string (unique identifier)
  - type: enum (primitive, mesh, articulated, etc.)
  - position: Vector3 (x, y, z coordinates)
  - rotation: Quaternion (orientation in 3D space)
  - material: MaterialConfig (visual properties)
  - physics_enabled: boolean (whether physics applies)

### SensorConfig
- **Attributes**:
  - sensor_type: enum (camera, lidar, imu, gps, etc.)
  - position: Vector3 (position relative to robot frame)
  - orientation: Quaternion (orientation relative to robot frame)
  - parameters: object (sensor-specific settings like FOV, range, etc.)
  - output_topic: string (ROS topic for sensor data)

## Perception Pipeline Entities

### PerceptionNode
- **Attributes**:
  - node_name: string (name of the ROS node)
  - algorithm_type: enum (vslam, stereo, object_detection, etc.)
  - input_topics: array of string (topics consumed by the node)
  - output_topics: array of string (topics published by the node)
  - gpu_accelerated: boolean (whether hardware acceleration is used)
  - performance_metrics: PerformanceMetrics (timing and accuracy data)

### PerformanceMetrics
- **Attributes**:
  - processing_time_ms: float (average processing time per frame)
  - fps: float (frames per second achieved)
  - accuracy_score: float (accuracy metric for the algorithm)
  - gpu_utilization: float (GPU usage percentage)
  - memory_usage_mb: int (memory consumption in MB)

## Navigation System Entities

### NavigationGoal
- **Attributes**:
  - goal_id: string (unique identifier)
  - position: Vector3 (target coordinates in map frame)
  - orientation: Quaternion (desired final orientation)
  - frame_id: string (coordinate frame reference)
  - timeout: float (time limit for reaching goal)

### PathPlan
- **Attributes**:
  - plan_id: string (unique identifier)
  - waypoints: array of Waypoint (sequence of navigation points)
  - global_cost: float (overall path cost)
  - computed_time: timestamp (when the path was computed)
  - status: enum (valid, invalid, partial, etc.)

### Waypoint
- **Attributes**:
  - position: Vector3 (coordinates in navigation space)
  - tolerance: float (acceptable deviation from exact position)
  - action: enum (move_through, pause, inspect, etc.)

## Synthetic Dataset Entities

### SyntheticSample
- **Attributes**:
  - sample_id: string (unique identifier)
  - sensor_type: enum (camera, lidar, etc.)
  - timestamp: timestamp (when sample was generated)
  - raw_data: binary (actual sensor data)
  - metadata: SampleMetadata (descriptive information)

### SampleMetadata
- **Attributes**:
  - scene_context: string (description of scene conditions)
  - lighting_conditions: string (lighting configuration)
  - occlusions: array of string (objects causing occlusions)
  - annotation: object (ground truth labels for training)

## Relationships

### Simulation to Perception
- A Virtual Scene contains multiple SceneObjects that serve as targets for perception algorithms
- SensorConfigs in a scene feed data to PerceptionNodes for processing
- PerformanceMetrics are generated by PerceptionNodes during processing

### Perception to Navigation
- PerceptionNodes provide environmental understanding used by navigation systems
- NavigationGoals may be influenced by perception data for obstacle avoidance
- PathPlans can be adjusted based on real-time perception inputs

### Simulation to Navigation
- Virtual Scenes provide the environment context for navigation planning
- SceneObjects act as obstacles or landmarks in navigation tasks
- Navigation performance can be measured within simulation environments

## Validation Rules

### From Requirements
- VR-001: All Virtual Scene configurations must include at least one sensor
- VR-002: PerceptionNode algorithms must publish to standard ROS topics
- VR-003: NavigationGoals must have valid coordinate frames
- VR-004: SyntheticSamples must include complete metadata for training purposes

## State Transitions

### Simulation Environment States
- DRAFT → VALIDATED → DEPLOYED
  - DRAFT: Initial creation, potentially incomplete
  - VALIDATED: Verified to work correctly in Isaac Sim
  - DEPLOYED: Used in educational exercises

### Perception Node States
- CONFIGURED → PROCESSING → ANALYZING → COMPLETED
  - CONFIGURED: Parameters set but not running
  - PROCESSING: Actively processing sensor data
  - ANALYZING: Evaluating results and performance
  - COMPLETED: Finished processing cycle

### Navigation States
- IDLE → PLANNING → EXECUTING → COMPLETED/FAILED
  - IDLE: Ready to accept navigation goals
  - PLANNING: Computing path to goal
  - EXECUTING: Following planned path
  - COMPLETED/FAILED: Goal reached or abandoned